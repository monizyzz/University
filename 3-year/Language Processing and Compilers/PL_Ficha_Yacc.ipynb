{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YM8FpHLtHaSH"
      },
      "source": [
        "# Ficha de Análise Sintática (Yacc) em Python\n",
        "\n",
        "Autor: Sofia Santos\n",
        "       com revisão de PRH (2023)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaFcMCTzHaSI"
      },
      "source": [
        "## Introdução\n",
        "\n",
        "A análise sintática, ou \"*parsing*\" em inglês, refere-se ao processo de analisar um texto, muitas vezes o código-fonte de um programa, para determinar a sua estrutura e significado.\n",
        "\n",
        "Em computação, o *parsing* é usado como componente chave no processo de compilação para converter código escrito numa linguagem de programação de alto nível para código executável pela máquina. Também na linguística, o *parsing* é usado para analisar frases em linguagem natural e determinar a sua estrutura sintática.\n",
        "\n",
        "Em Python, podemos fazer análise sintática de várias formas. A que iremos utilizar nas aulas, tal como na análise léxica, recorre ao módulo **Ply**, mais especificamente à ferramenta **Yacc**.\n",
        "\n",
        "O **Yacc** usa uma técnica de *parsing* conhecida como *LR-parsing* (ou *shift-reduce* parsing). O L significa que o *input* é lido da esquerda para a direita e o R significa que as regras da gramática são \"reduzidas\" do lado direito de cada regra de derivação para o seu lado esquerdo.\n",
        "\n",
        "Dentro do módulo `Ply`, usamos a ferramenta `yacc.py` para fazer análise sintática."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7FeTVrMHaSJ"
      },
      "outputs": [],
      "source": [
        "import ply.yacc as yacc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVnPt9yCHaSJ"
      },
      "source": [
        "Para fazer análise sintática, precisamos primeiro de fazer análise léxica.\n",
        "\n",
        "Assim, vamos pegar no exemplo usado na ficha anterior e estendê-lo para realizar também o *parsing* de expressões aritméticas, passando a funcionar como uma calculadora."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3-Z4d_DHaSJ"
      },
      "outputs": [],
      "source": [
        "import ply.lex as lex\n",
        "\n",
        "tokens = (\n",
        "    'NUMBER',\n",
        "    'PLUS',\n",
        "    'MINUS',\n",
        "    'TIMES',\n",
        "    'DIVIDE',\n",
        "    'LPAREN',\n",
        "    'RPAREN'\n",
        ")\n",
        "\n",
        "t_PLUS = r'\\+'\n",
        "t_MINUS = r'\\-'\n",
        "t_TIMES = r'\\*'\n",
        "t_DIVIDE = r'\\/'\n",
        "t_LPAREN = r'\\('\n",
        "t_RPAREN = r'\\)'\n",
        "\n",
        "def t_NUMBER(t):\n",
        "    r'\\d+'\n",
        "    t.value = int(t.value)\n",
        "    return t\n",
        "\n",
        "t_ignore = ' \\n\\t'\n",
        "\n",
        "def t_error(t):\n",
        "    print(f\"Carácter ilegal {t.value[0]}\")\n",
        "    t.lexer.skip(1)\n",
        "\n",
        "lexer = lex.lex()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLwqA9VtHaSK"
      },
      "source": [
        "O parser precisa de ter acesso aos tokens. Caso o tokenizer esteja definido noutro ficheiro, devemos importar a variável.\n",
        "\n",
        "```py\n",
        "from [nome_do_tokenizer] import tokens\n",
        "```\n",
        "supondo que o analisador léxico anterior tinha sido gravado num ficheiro com o nome `calculadora_lex.py` a importação que teremos de fazer seria:\n",
        "```py\n",
        "from calculadora_lex import tokens\n",
        "```\n",
        "\n",
        "Depois, apenas precisamos de definir as regras da gramática da Calculadora.\n",
        "\n",
        "Se apenas pretendermos fazer a análise sintática, sem qualquer ação que não seja de validar se a frase de entrada tem a estrutura correta, isto é, se forma uma frase válida da linguagem da Calculadora, bastará escrever uma única função, com todas as regras de derivação da dita gramática, em Python na sintaxe do *ply* como se mostra a seguir (de notar que o prefixo `p_` é obrigatório no nome dessa função):\n",
        "\n",
        "```py\n",
        "def p_grammar(p):\n",
        "    \"\"\"\n",
        "    expression : expression PLUS term\n",
        "    expression : expression MINUS term\n",
        "    expression : term\n",
        "    term       : term TIMES factor\n",
        "    term       : term DIVIDE factor\n",
        "    term       : factor\n",
        "    factor     : NUMBER\n",
        "    factor     : LPAREN expression RPAREN\n",
        "    \"\"\"\n",
        "```\n",
        "\n",
        "Adicionalmente o `yacc` do **Ply** exige que se defina uma função para estabelecer o comportament do *parser* caso encontre um erro sintático na frase de entrada.\n",
        "\n",
        "```py\n",
        "def p_error(p):\n",
        "  print(\"Erro sintático na entrada ao ler o símbolo \",p)\n",
        "```\n",
        "\n",
        "Porém caso se queira ir fazendo ações ao longo do reconhecimento léxico-sintático para produzir uma *saída* ou *resultado*, neste caso, para ir calculando o valor da expressão e escevê-lo no fim, é necessário partir a gramática em regras e definir uma função de reconhecimento para cada uma:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5q7JRxHQHaSK"
      },
      "outputs": [],
      "source": [
        "def p_expression_plus(p):\n",
        "    'expression : expression PLUS term'\n",
        "    p[0] = p[1] + p[3]\n",
        "\n",
        "def p_expression_minus(p):\n",
        "    'expression : expression MINUS term'\n",
        "    p[0] = p[1] - p[3]\n",
        "\n",
        "def p_expression_term(p):\n",
        "    'expression : term'\n",
        "    p[0] = p[1]\n",
        "\n",
        "def p_term_times(p):\n",
        "    'term : term TIMES factor'\n",
        "    p[0] = p[1] * p[3]\n",
        "\n",
        "def p_term_div(p):\n",
        "    'term : term DIVIDE factor'\n",
        "    p[0] = p[1] / p[3]\n",
        "\n",
        "def p_term_factor(p):\n",
        "    'term : factor'\n",
        "    p[0] = p[1]\n",
        "\n",
        "def p_factor_num(p):\n",
        "    'factor : NUMBER'\n",
        "    p[0] = p[1]\n",
        "\n",
        "def p_factor_expr(p):\n",
        "    'factor : LPAREN expression RPAREN'\n",
        "    p[0] = p[2]\n",
        "\n",
        "def p_error(p):\n",
        "    print(\"Erro sintático no input!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "magOO0JoHaSK"
      },
      "source": [
        "Cada função corresponde ao nome de uma regra da gramática, representada por um símbolo não-terminal do lado esquerdo e uma sequência de não-terminais e *tokens* do lado direito.\n",
        "\n",
        "Caso um não-terminal seja definido à custa de outros não-terminais, os seus valores podem ser obtidos através de `p[i]`, em que `i` é a posição do não-terminal na regra. O valor dos terminais é o valor definido no *tokenizer*.\n",
        "\n",
        "Depois de executar a função, o valor do não-terminal à esquerda irá corresponder ao valor de `p[0]`.\n",
        "\n",
        "Por exemplo, em\n",
        "\n",
        "```py\n",
        "def p_expression_plus(p):\n",
        "    'expression : expression PLUS term'\n",
        "    #   ^            ^        ^    ^\n",
        "    #  p[0]         p[1]     p[2] p[3]\n",
        "\n",
        "    p[0] = p[1] + p[3]\n",
        "```\n",
        "\n",
        "o valor de `p[2]` será \"+\", e o valor de `p[3]` será o valor de `p[0]` atribuído na regra `p_term_` correspondente.\n",
        "\n",
        "A primeira regra definida determina o símbolo inicial da gramática. Neste caso é `expression`, o que significa que o *input* dado ao parser será reduzido até esta regra ser atingida ou até haver um erro do qual o parser não consiga recuperar.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q30CRzhrHaSL"
      },
      "source": [
        "Depois de termos estas regras definidas, podemos correr o nosso *parser*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Se5jiuTZHaSL"
      },
      "outputs": [],
      "source": [
        "parser = yacc.yacc()\n",
        "\n",
        "while s := input('calc > '):\n",
        "   result = parser.parse(s)\n",
        "   print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YztDDQtkHaSL"
      },
      "source": [
        "No caso de termos uma regra como:\n",
        "\n",
        "```py\n",
        "expression : expression PLUS expression\n",
        "           | expression MINUS expression\n",
        "           | expression TIMES expression\n",
        "           | expression DIVIDE expression\n",
        "           | LPAREN expression RPAREN\n",
        "           | NUMBER\n",
        "```\n",
        "\n",
        "se dermos ao *parser* uma expressão como \"5 + 2 * 5\", quando ele já tiver lido \"5 + 2\", não saberá se primeiro deve reduzir a adição ou ler o *token* da multiplicação, criando um conflito *shift/reduce*.\n",
        "\n",
        "Em vez de estarmos a definir duas regras diferentes, como fizemos acima, podemos definir a precedência de cada token/terminal da seguinte forma:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llI_ePlFHaSL"
      },
      "outputs": [],
      "source": [
        "precedence = (\n",
        "    ('left', 'PLUS', 'MINUS'),\n",
        "    ('left', 'TIMES', 'DIVIDE'),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ql3Whjx0HaSL"
      },
      "source": [
        "Agora, como o *token* da multiplicação tem maior precedência do que o da adição, vai haver um *shift* em vez de uma redução no exemplo acima, sem ambiguidades."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjVkODezHaSL"
      },
      "source": [
        "Para além de precedência à esquerda, podemos definir precedência à direita (útil para operadores unários, como a inversão de sinal) ou precedência não associativa, na qual estamos a dizer que não podemos combinar operadores daquele tipo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqjSliZiHaSL"
      },
      "outputs": [],
      "source": [
        "precedence = (\n",
        "    ('nonassoc', 'LESSTHAN', 'GREATERTHAN'),  # Nonassociative operators (a < b < c)\n",
        "    ('left', 'PLUS', 'MINUS'),\n",
        "    ('left', 'TIMES', 'DIVIDE'),\n",
        "    ('right', 'UMINUS'),            # Unary minus operator (-5)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXhJojuTHaSL"
      },
      "source": [
        "A documentação completa do Yacc pode ser consultada em: https://ply.readthedocs.io/en/latest/ply.html#yacc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EC4W_CvgHaSM"
      },
      "source": [
        "## Exercícios\n",
        "\n",
        "###0. BibTeX (resolvido)\n",
        "\n",
        "Retome o exercício 4 do GColab 'PL_Ficha_Lex' em que se pede para reconhecer os ´simbolos terminais de uma base de dados textual, escrita em formato BibTeX, com diversas referências bibliográficas para serem citadas dentro de documentos LaTeX.\n",
        "\n",
        "Nesse exercício foi escrito, num ficheiro 'bibtex_lex.py', um analisador que reconhece os símbolos terminais variáveis (classes terminais): TIPOreg, PAL, SEP e TEXTO\n",
        "\n",
        "e reconhece os Sinais (Literals): '{', '}' e ','\n",
        "\n",
        "Agora pretende-se recorrer a esse Analisador Léxico para criar um Parser (Analisador Sintático) que aceite um ficheiro BibTeX completo com uma ou mais refências.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# ficheiro 'bibtex_gic.py'\n",
        "#\n",
        "#    Reconhecedor Sintático para BibTeX\n",
        "#\n",
        "import ply.yacc as yacc\n",
        "from bibtex_lex import tokens\n",
        "\n",
        "def p_grammar(p):\n",
        "\t\"\"\"\n",
        "    bibtex      : referencias\n",
        "    referencias : referencias referencia\n",
        "                |\n",
        "\t  referencia  : TIPOreg '{' chaveCita ',' campos '}'\n",
        "    chaveCita   : PAL\n",
        "\t    campos      : campos ',' campo\n",
        "\t    campos      : campo\n",
        "\t    campo       : nomeCampo SEP  valorCampo\n",
        "        nomeCampo   : PAL\n",
        "        valorCampo  : TEXTO\n",
        "\t\"\"\"\n",
        "\n",
        "def p_error(p):\n",
        "    print(\"Syntax error in input!\",p)\n",
        "    parser.success=False\n",
        "\n",
        "# Geração do Parser\n",
        "parser = yacc.yacc()\n",
        "parser.success=True\n",
        "\n",
        "# Leitura do ficheiro de texto-fonte\n",
        "source = \"\"\n",
        "f = open(\"bibtex.bib\",encoding=\"utf-8\")\n",
        "for linha in f:\n",
        "\tsource += linha\n",
        "\n",
        "# Parsing do texto-fonte e apresentação do resultado\n",
        "parser.parse(source)\n",
        "#print(source)\n",
        "if parser.success:\n",
        "   print('Parsing completed!')\n",
        "else:\n",
        "   print('Parsing failed!')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DTUQY5Uo4hQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2qS7GvgF8HfG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###0. BibTeX -- continuação 1\n",
        "\n",
        "Transforme a GIC anterior numa GT de modo a calcular o numero de Referências existentes na sua Base de Dados BibTeX.\n"
      ],
      "metadata": {
        "id": "qRAG5E5-8wz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#\n",
        "# ficheiro 'bibtex_gic.py'\n",
        "#\n",
        "#    Reconhecedor Sintático para BibTeX\n",
        "#\n",
        "import ply.yacc as yacc\n",
        "from bibtex_lex import tokens\n",
        "\n",
        "def p_bibtex(p):\n",
        "    \"bibtex      : referencias\"\n",
        "    p[0] = p[1]\n",
        "\n",
        "def p_refs_varias(p):\n",
        "    \"referencias : referencias referencia\"\n",
        "    p[0] = p[1] + 1\n",
        "\n",
        "def p_refs_vazia(p):\n",
        "    \"referencias : \"\n",
        "    p[0] = 0\n",
        "\n",
        "def p_ref(p):\n",
        "    \"\"\"\n",
        "    referencia  : TIPOreg '{' PAL ',' campos '}'\n",
        "    campos : campos ',' campo\n",
        "\t        | campo\n",
        "\t  campo : PAL SEP  TEXTO\n",
        "    \"\"\"\n",
        "\n",
        "def p_error(p):\n",
        "    parser.success=False\n",
        "\n",
        "parser = yacc.yacc()\n",
        "parser.success= True\n",
        "\n",
        "source = \"\"\n",
        "f = open(\"bibtex.bib\",encoding=\"utf-8\")\n",
        "for linha in f:\n",
        "\tsource += linha\n",
        "\n",
        "count = parser.parse(source) # processa o texto-fonte\n",
        "if parser.success:\n",
        "   print(\"Referencias reconhecidas = \",count)\n",
        "else:\n",
        "   print('Erros Sintáticos!')\n",
        "\n"
      ],
      "metadata": {
        "id": "Z2L9Y6zJWGeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###0. BibTeX -- continuação 2\n",
        "\n",
        "Transforme a GT anterior numa outra GT de modo a: calcular o numero de Referências existentes na sua Base de Dados BibTeX; e a validar a existência de *chaves de citação* repetidas."
      ],
      "metadata": {
        "id": "aI4H1QeWZLSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# ficheiro 'bibtex_gic.py'\n",
        "#\n",
        "#    Reconhecedor Sintático/Semântico para BibTeX\n",
        "#\n",
        "import ply.yacc as yacc\n",
        "from bibtex_lex import tokens\n",
        "\n",
        "def p_bibtex(p):\n",
        "    \"bibtex      : referencias\"\n",
        "    p[0] = p[1]\n",
        "\n",
        "def p_refs_varias(p):\n",
        "    \"referencias : referencias referencia\"\n",
        "    p[0] = p[1] + 1\n",
        "\n",
        "def p_refs_vazia(p):\n",
        "    \"referencias : \"\n",
        "    p[0] = 0\n",
        "\n",
        "def p_ref(p):\n",
        "    \"referencia  : TIPOreg '{' PAL ',' campos '}' \"\n",
        "    if (p[3] in parser.chaves):\n",
        "       parser.success = False\n",
        "       parser.erros += \"\\nErros semantico! chave de citação repetida » \"+p[3]\n",
        "    else:\n",
        "       parser.chaves += [p[3]]\n",
        "\n",
        "def p_campos(p):\n",
        "    \"\"\"campos : campos ',' campo\n",
        "\t        | campo \"\"\"\n",
        "def p_campo(p):\n",
        "\t\"campo : PAL SEP  TEXTO\"\n",
        "\n",
        "def p_error(p):\n",
        "    parser.success=False\n",
        "\n",
        "parser = yacc.yacc()\n",
        "parser.success= True\n",
        "parser.erros  = \"\"\n",
        "parser.chaves = []\n",
        "\n",
        "source = \"\"\n",
        "#for linha in sys.stdin:\n",
        "#\tsource += linha\n",
        "f = open(\"bibtex.txt\",encoding=\"utf-8\")\n",
        "for linha in f:\n",
        "\tsource += linha\n",
        "\n",
        "count = parser.parse(source) # processa o texto-fonte\n",
        "if parser.success:\n",
        "   print('Parsing completed!')\n",
        "   print(\"Referencias reconhecidas = \",count)\n",
        "else:\n",
        "   print('Processing failed! Syntax or Semantic Errors')\n",
        "   print(parser.erros)\n"
      ],
      "metadata": {
        "id": "CHe618HFaVYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Lista de compras\n",
        "\n",
        "Constroi um analisador sintático capaz de ler uma lista de compras, organizada por secções de um supermercado (CARNE, PEIXE, LEGUMES, BEBIDAS, etc.), e de validar sintaticamente essa lista.\n",
        "\n",
        "Exemplo de uma lista de compras em que cada produto necessário de cada secção tem um **número de código, nome, preço unitário** e **quantidade a comprar** é apresentado a seguir:\n",
        "\n",
        "---\n",
        "```\n",
        "CARNE :\n",
        "  - 1 :: Bife :: 10.00 :: 1;\n",
        "  - 2 :: Panado :: 5.00 :: 4;\n",
        "  - 3 :: Hambúrguer :: 8.00 :: 3;\n",
        "  - 4 :: Almôndegas :: 7.00 :: 5;\n",
        "\n",
        "BEBIDA :\n",
        "  - 5 :: Água :: 0.40 :: 16;\n",
        "  - 6 :: Sumo :: 1.50 :: 9;\n",
        "  - 7 :: Refrigerante :: 1.80 :: 10;\n",
        "\n",
        "FRUTA :\n",
        "  - 8 :: Maçã :: 0.60 :: 20;\n",
        "  - 9 :: Banana :: 0.50 :: 15;\n",
        "  - 10 :: Laranja :: 0.80 :: 18;\n",
        "  - 11 :: Pêssego :: 0.70 :: 22;\n",
        "  - 12 :: Uva :: 0.90 :: 17;\n",
        "\n",
        "LEGUMES :\n",
        "  - 13 :: Alface :: 1.00 :: 25;\n",
        "  - 14 :: Tomate :: 0.75 :: 23;\n",
        "  - 15 :: Cebola :: 0.50 :: 28;\n",
        "  - 16 :: Batata :: 0.30 :: 30;\n",
        "  - 17 :: Cenoura :: 0.40 :: 26;\n",
        "\n",
        "PASTELARIA :\n",
        "  - 18 :: Bolo de Chocolate :: 3.50 :: 1;\n",
        "  - 19 :: Croissant :: 1.20 :: 14;\n",
        "  - 20 :: Pastel de Nata :: 1.00 :: 5;\n",
        "  - 21 :: Donut :: 0.80 :: 13;\n",
        "```\n",
        "---\n",
        "Numa segunda etape, o processador a construir a partir da GIC escrita na fase anterior, deve calcular, para além do **custo total das compras**, o **número de items** listados, e o **total de artigos** a comprar.\n",
        "\n",
        "Numa última etape, pretende-se que enriqueça o processador anterior com um Analisador Semântico  que detete três tipos de erros de inconsistência lógica da lista de compras e que só apresente os valores calculados se a frase for *bem reconhecida* (isto é, *se fizer sentido*). Os erros semânticos a detetar são:\n",
        "+ nomes de secções repetidos;\n",
        "+ mais do que uma referência ao mesmo produto  (mesmo código, nome e preço);\n",
        "+ uso do mesmo código para produtos diferentes (com nomes ou preços unitários diversos).\n",
        "\n",
        "Abaixo mostra-se  uma frase com todos estes tipos de erros semânticos:\n",
        "\n",
        "```\n",
        "CARNE :\n",
        "    - 1 :: Bife :: 10.00 :: 4;\n",
        "    - 1 :: Bife :: 10.00 :: 1;\n",
        "    - 2 :: Lombo :: 10.00 :: 4;\n",
        "    - 2 :: Lombo :: 12.00 :: 1;\n",
        "    - 3 :: Figado :: 2.00 :: 1;\n",
        "\n",
        "CARNE :\n",
        "    - 3 :: Costoleta :: 2.00 :: 1;\n",
        "    - 1 :: Bife :: 10.00 :: 7;\n",
        "\n",
        "PEIXE :\n",
        "    - 77 :: Pescada :: 20.00 :: 2;\n",
        "```\n"
      ],
      "metadata": {
        "id": "Uw-QQ9PbhBpz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wRB2_V9HaSM"
      },
      "source": [
        "### 2. Linguagem lógica\n",
        "\n",
        "Define um *parser* para uma linguagem de lógica simples que pode ter proposições, negações, conjunções, disjunções, implicações, equivalências e parênteses. A linguagem usa letras maiúsculas para proposições, ~ para negações, & para conjunções, | para disjunções, -> para implicações e <-> para equivalências. Assim, uma frase válida nesta linguagem poderia ser `P -> (Q & R) | ~S`. Este *parser* deve fazer parte de um programa que pede ao utilizador uma frase, faz a sua análise sintática, pergunta quais são os valores lógicos de cada proposição que apareça na frase e por fim utiliza o *parser* para determinar o valor lógico da expressão lida."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Tabela para CSV\n",
        "\n",
        "Define um parser que converte uma tabela, escrita em formato textual, para um ficheiro CSV.\n",
        "\n",
        "Exemplo de uma tabela em formato textual:\n",
        "\n",
        "---\n",
        "```\n",
        "| Nome        | Idade | Género      | Altura | Ocupação         |\n",
        "|-------------|-------|-------------|--------|------------------|\n",
        "| Alex        | 32    | Não-binário | 1.72   | Desenvolvimento  |\n",
        "| Avery       | 29    | Feminino    | 1.85   | Marketing        |\n",
        "| Casey       | 27    | Masculino   | 1.80   | Apoio ao cliente |\n",
        "| David       | 40    | Masculino   | 1.76   | Gerente          |\n",
        "| Emily       | 31    | Feminino    | 1.62   | Designer         |\n",
        "| Frank       | 25    | Masculino   | 1.81   | Apoio ao cliente |\n",
        "| Grace       | 38    | Feminino    | 1.68   | Vendas           |\n",
        "| Harper      | 33    | Não-binário | 1.70   | Desenvolvimento  |\n",
        "| Ivan        | 30    | Masculino   | 1.77   | Apoio ao cliente |\n",
        "| Jane        | 29    | Feminino    | 1.74   | Designer         |\n",
        "| Kim         | 35    | Feminino    | 1.79   | Gerente          |\n",
        "| Liam        | 28    | Masculino   | 1.83   | Marketing        |\n",
        "| Morgan      | 26    | Não-binário | 1.67   | Desenvolvimento  |\n",
        "| Nathan      | 34    | Masculino   | 1.76   | Apoio ao cliente |\n",
        "| Olivia      | 36    | Feminino    | 1.75   | Gerente          |\n",
        "| Pat         | 37    | Não-binário | 1.78   | Designer         |\n",
        "| Quinn       | 27    | Não-binário | 1.68   | Marketing        |\n",
        "| Rachel      | 39    | Feminino    | 1.69   | Desenvolvimento  |\n",
        "| Sam         | 23    | Não-binário | 1.70   | Apoio ao cliente |\n",
        "| Taylor      | 31    | Não-binário | 1.81   | Vendas           |\n",
        "```\n",
        "---\n",
        "\n",
        "Extra: permite que o parser consiga também converter uma tabela para um ficheiro JSON."
      ],
      "metadata": {
        "id": "tPE7Qa3xnj74"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Árvores binárias\n",
        "\n",
        "Considera que uma árvore binária pode ser representada segundo um formato textual em que `()` representa uma árvore vazia e `( e l r )` representa uma árvore com raiz `e`, uma árvore `l` à sua esquerda e uma árvore `r` à sua direita.\n",
        "\n",
        "Por exemplo, `( 5 (3 (1 () ()) ()) (8 () (10 () ())))` representa uma árvore de raiz 5, com uma árvore de raiz 3 à sua esquerda e uma árvore de raiz 8 à sua direita.\n",
        "\n",
        "Escreva a Gramática que permite reconhecer frases como a do exemplo acima para descrever árvores binárias e, com base nessa GIC,  gere um analisador sintático que reconheça as frases cooretamente escritas.\n",
        "\n",
        "Com base nesse *parser* desenvolva um processador capaz de converter esta representação textual numa representação em JSON da forma:\n",
        "\n",
        "```Jason\n",
        "ARVBIN =\n",
        "null\n",
        "|\n",
        "{\n",
        "        \"root\": VALOR,\n",
        "        \"left\": ARVBIN | null,\n",
        "        \"right\": ARVBIN | null\n",
        "}\n",
        "```\n",
        "Adicionalmente,\n",
        "cria uma  árvore binária  em Python que represente a árvore\n",
        "descrita pelo texto de entrada.\n",
        "Para isso, deves definir uma classe em Python que represente uma árvore binária."
      ],
      "metadata": {
        "id": "o4S6-7S5mDKh"
      }
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}